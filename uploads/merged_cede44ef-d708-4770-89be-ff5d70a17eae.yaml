project_name: new_project
folders:
- name: .
  files:
  - name: .env
    content: '''''''구조정보 .env''''''

      내부 구조(키)

      OPENAI_API_KEY

      AZURE_OPENAI_API_KEY

      AZURE_OPENAI_ENDPOINT

      AZURE_OPENAI_DEPLOYMENT_ID'
  - name: file_generator.py
    content: "'''file_generator.py'''\nimport os\nimport shutil\nimport yaml\nimport\
      \ json\n\nclass ProjectCreator:\n    def __init__(self, yaml_content):\n   \
      \     self.data = yaml.safe_load(yaml_content)\n        self.project_name =\
      \ self.data.get('project_name', 'default_project')\n        self.project_path\
      \ = os.path.join(os.getcwd(), self.project_name)\n\n    def create_project_structure(self):\n\
      \        # Create project directory if it doesn't exist\n        if not os.path.exists(self.project_path):\n\
      \            os.makedirs(self.project_path)\n        \n        # Create files\
      \ and folders\n        self._create_files(self.data.get('folders', []), self.project_path)\n\
      \        \n        # Compress the project folder and return the path\n     \
      \   zip_file_path = self._compress_project()\n        return zip_file_path\n\
      \n    def _create_files(self, folders, base_path):\n        for folder in folders:\n\
      \            folder_path = os.path.join(base_path, folder['name'])\n       \
      \     if not os.path.exists(folder_path):\n                os.makedirs(folder_path)\n\
      \            for file in folder.get('files', []):\n                file_path\
      \ = os.path.join(folder_path, file['name'])\n                with open(file_path,\
      \ 'w', encoding='utf-8') as f:\n                    f.write(file['content'])\n\
      \            if 'subfolders' in folder:\n                self._create_files(folder['subfolders'],\
      \ folder_path)\n\n    def _compress_project(self):\n        zip_file_name =\
      \ f\"{self.project_name}.zip\"\n        zip_file_path = os.path.join(os.getcwd(),\
      \ zip_file_name)\n        \n        # Create a zip archive of the project folder\n\
      \        shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', self.project_path)\n\
      \        \n        # Clean up the unzipped folder\n        shutil.rmtree(self.project_path)\n\
      \        \n        return zip_file_path"
  - name: file_merger.py
    content: "'''file_merger.py'''\nimport os\nimport json\nimport yaml\nfrom flask\
      \ import url_for\n\nclass FileMerger:\n    def __init__(self):\n        self.extension_list\
      \ = ['.py', '.json', '.env']\n        self.structure_extensions = ['.json',\
      \ '.env']\n        self.output_file = \"\"\n        self.source_folder = \"\"\
      \n        self.is_running = False\n\n    def load_config(self, base_path):\n\
      \        config_file = os.path.join(base_path, \"config/config.json\")\n   \
      \     if os.path.exists(config_file):\n            with open(config_file, 'r',\
      \ encoding='utf-8') as config:\n                config_data = json.load(config)\n\
      \                self.extension_list = config_data.get(\"extensions\", self.extension_list)\n\
      \                self.structure_extensions = config_data.get(\"structure_extensions\"\
      , self.structure_extensions)\n        else:\n            self.save_config()\n\
      \n    def save_config(self, base_path):\n        config_data = {\n         \
      \   \"extensions\": self.extension_list,\n            \"structure_extensions\"\
      : self.structure_extensions\n        }\n        with open(os.path.join(base_path,\
      \ \"config/config.json\"), 'w', encoding='utf-8') as config:\n            json.dump(config_data,\
      \ config, ensure_ascii=False, indent=4)\n\n    def merge_files(self, source_folder,\
      \ output_file):\n        self.source_folder = source_folder\n        self.output_file\
      \ = output_file\n        self.is_running = True\n        try:\n            project_data\
      \ = {\"project_name\": \"new_project\", \"folders\": []}\n            \n   \
      \         for root, dirs, files in os.walk(self.source_folder):\n          \
      \      folder_data = {\"name\": os.path.relpath(root, self.source_folder), \"\
      files\": []}\n                for filename in files:\n                    if\
      \ any(filename.endswith(ext) for ext in self.extension_list):\n            \
      \            file_path = os.path.join(root, filename)\n                    \
      \    relative_path = os.path.relpath(file_path, self.source_folder)\n      \
      \                  if filename.endswith('.json'):\n                        \
      \    with open(file_path, 'r', encoding='utf-8') as infile:\n              \
      \                  structure_info = json.load(infile)\n                    \
      \            folder_data[\"files\"].append({\n                             \
      \       \"name\": filename,\n                                    \"content\"\
      : f\"'''구조정보 {relative_path}'''\\n내부 구조(키)\\n\" + \"\\n\".join(structure_info.keys())\
      \ + \"\\n\\n\" + json.dumps(structure_info, indent=4)\n                    \
      \            })\n                        elif filename.endswith('.env'):\n \
      \                           with open(file_path, 'r', encoding='utf-8') as infile:\n\
      \                                env_content = infile.read()\n             \
      \                   env_keys = [line.split('=')[0] for line in env_content.splitlines()\
      \ if '=' in line]\n                                folder_data[\"files\"].append({\n\
      \                                    \"name\": filename,\n                 \
      \                   \"content\": f\"'''구조정보 {relative_path}'''\\n내부 구조(키)\\\
      n\" + \"\\n\".join(env_keys)\n                                })\n         \
      \               else:\n                            with open(file_path, 'r',\
      \ encoding='utf-8') as infile:\n                                folder_data[\"\
      files\"].append({\n                                    \"name\": filename,\n\
      \                                    \"content\": f\"'''{relative_path}'''\\\
      n\" + infile.read()\n                                })\n                \n\
      \                if folder_data[\"files\"]:\n                    project_data[\"\
      folders\"].append(folder_data)\n            \n            with open(self.output_file,\
      \ 'w', encoding='utf-8') as outfile:\n                yaml.dump(project_data,\
      \ outfile, allow_unicode=True, sort_keys=False)\n                \n        \
      \    # Assuming the server is configured to serve files from the current directory\n\
      \            file_url = url_for('static', filename=os.path.basename(self.output_file),\
      \ _external=True)\n            return {\"status\": \"success\", \"file_url\"\
      : file_url}\n        except Exception as e:\n            return {\"status\"\
      : \"error\", \"message\": str(e)}\n        finally:\n            self.is_running\
      \ = False"
  - name: langchain_setup.py
    content: "'''langchain_setup.py'''\nimport json\nimport os\nimport requests\n\
      from dotenv import load_dotenv\nfrom langchain_community.llms import OpenAI\n\
      from langchain.chains import LLMChain\n\n# 환경 변수 로드\nload_dotenv()\n\ndef load_config(config_file):\n\
      \    \"\"\"Load configuration from a JSON file.\"\"\"\n    with open(config_file,\
      \ 'r') as file:\n        return json.load(file)\n\ndef create_tool_chain(model_name,\
      \ provider):\n    \"\"\"Create a LangChain tool for interacting with OpenAI\
      \ or Azure OpenAI.\"\"\"\n    \n    if provider == 'openai':\n        api_key\
      \ = os.getenv('OPENAI_API_KEY')\n        if not api_key:\n            raise\
      \ ValueError(\"OPENAI_API_KEY not set in environment variables.\")\n       \
      \ openai_llm = OpenAI(api_key=api_key, model_name=model_name)\n        \n  \
      \      def call_openai_tool(prompt):\n            response = openai_llm(prompt=prompt)\n\
      \            return response['choices'][0]['text'].strip()\n    \n        return\
      \ lambda prompt: call_openai_tool(prompt)\n    \n    elif provider == 'azure':\n\
      \        azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n        azure_api_key\
      \ = os.getenv('AZURE_OPENAI_API_KEY')\n        deployment_id = os.getenv('AZURE_OPENAI_DEPLOYMENT_ID')\
      \  # 배포 ID를 환경 변수로 추가\n\n        if not azure_endpoint or not azure_api_key\
      \ or not deployment_id:\n            raise ValueError(\"AZURE_OPENAI_ENDPOINT,\
      \ AZURE_OPENAI_API_KEY, or AZURE_OPENAI_DEPLOYMENT_ID not set in environment\
      \ variables.\")\n        \n        def call_azure_tool(prompt):\n          \
      \  headers = {\n                'Content-Type': 'application/json',\n      \
      \          'api-key': azure_api_key\n            }\n            payload = {\n\
      \                'messages': [\n                    {\n                    \
      \    'role': 'user',\n                        'content': prompt\n          \
      \          }\n                ],\n                'temperature': 0.7,\n    \
      \            'top_p': 0.95,\n                'max_tokens': 800\n           \
      \ }\n            url = f'{azure_endpoint}/openai/deployments/{deployment_id}/chat/completions?api-version=2024-02-15-preview'\n\
      \            response = requests.post(url, headers=headers, json=payload)\n\
      \            if response.status_code == 200:\n                response_data\
      \ = response.json()\n                return response_data['choices'][0]['message']['content'].strip()\n\
      \            else:\n                response.raise_for_status()  # Raise an\
      \ exception for HTTP errors\n        \n        return lambda prompt: call_azure_tool(prompt)\n\
      \    \n    else:\n        raise ValueError(\"Unsupported provider: Only 'openai'\
      \ and 'azure' are supported.\")\n\ndef setup_langchain():\n    \"\"\"Setup LangChain\
      \ with configuration from a JSON file.\"\"\"\n    config = load_config('config.json')\n\
      \    model_name = config['model_name']\n    provider = config['provider']\n\
      \    tool_chain = create_tool_chain(model_name, provider)\n    return tool_chain\n"
  - name: main.py
    content: "'''main.py'''\nimport sys\nimport yaml\nfrom langchain_setup import\
      \ setup_langchain\n\ndef run_project_creation(yaml_content):\n    tool_chain\
      \ = setup_langchain()\n    result = tool_chain(yaml_content)\n    print(result)\n\
      \nif __name__ == '__main__':\n    if len(sys.argv) != 2:\n        print(\"Usage:\
      \ python main.py <yaml_file>\")\n        sys.exit(1)\n\n    yaml_file_path =\
      \ sys.argv[1]\n\n    with open(yaml_file_path, 'r', encoding='utf-8') as yaml_file:\n\
      \        yaml_content = yaml_file.read()\n\n    run_project_creation(yaml_content)"
